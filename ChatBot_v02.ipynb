{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNI_VJrEvFgZ"
      },
      "source": [
        "# Q&A Chat Bot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QdnwdAfSDvb",
        "outputId": "ef5d730c-6240-453d-9e1b-2d57a3ae13b1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MBFMZW0vFgl"
      },
      "source": [
        "## Loading the Data\n",
        "\n",
        "We work with the Babi Data Set from Facebook Research.\n",
        "\n",
        "- Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n",
        "  \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\n",
        "  http://arxiv.org/abs/1502.05698\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "x5nXFjZGvFgn"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "vqPd1cmFvFgp"
      },
      "outputs": [],
      "source": [
        "# Unpickling file for training data\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/6120/Project/train_qa.txt\", \"rb\") as fp:\n",
        "    train_data =  pickle.load(fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "-4yrtDeWvFgq"
      },
      "outputs": [],
      "source": [
        "# Unpickling file for testing data\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/6120/Project/test_qa.txt\", \"rb\") as fp:\n",
        "    test_data =  pickle.load(fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAY1-_fmvFgs"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZhmG5jVvFgt"
      },
      "source": [
        "## Exploring the Format of the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtV-SD7xvFgy",
        "outputId": "a82c7431-a605-4695-a009-d5e466eae287"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "type(train_data)\n",
        "type(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDHqOy_LvFg0",
        "outputId": "2e101fc6-01c5-43d6-8b5e-6d4409e12082"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "len(train_data)\n",
        "len(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOCCXOoJvFg1",
        "outputId": "5d4b237c-5105-4d8b-d406-266f11b89658"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Mary',\n",
              "  'moved',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bathroom',\n",
              "  '.',\n",
              "  'Sandra',\n",
              "  'journeyed',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bedroom',\n",
              "  '.'],\n",
              " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
              " 'no')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Hsl6COyHvFg2",
        "outputId": "452b636d-614e-4bf3-889c-037e70785e2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "' '.join(train_data[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5Y6hI5aAvFg3",
        "outputId": "6f7067f0-74c4-45c5-c4a0-80e1103ca910"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Is Sandra in the hallway ?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "' '.join(train_data[0][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "UYLKOadNvFg3",
        "outputId": "b27ef93b-332d-48a0-9ea7-8cc22ca54d83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'no'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "train_data[0][2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o615MsRevFg4"
      },
      "source": [
        "-----\n",
        "\n",
        "## Setting up Vocabulary of All Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "id": "7GppqFyjvFg5"
      },
      "outputs": [],
      "source": [
        "# Create a set that holds the vocab words\n",
        "vocab = set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "id": "kWHl9-tEvFg6"
      },
      "outputs": [],
      "source": [
        "all_data = train_data + test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "id": "zyVdV_EovFg6"
      },
      "outputs": [],
      "source": [
        "for story, question , answer in all_data:\n",
        "    vocab = vocab.union(set(story))\n",
        "    vocab = vocab.union(set(question))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "id": "hYWssolhvFg7"
      },
      "outputs": [],
      "source": [
        "vocab.add('no')\n",
        "vocab.add('yes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oraHG-xgvFg8",
        "outputId": "ed64571a-0f03-4e10-d51f-c7161f7c3e3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "id": "GUeon11ivFg8"
      },
      "outputs": [],
      "source": [
        "vocab_len = len(vocab) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "id": "piUBJkiFvFg9"
      },
      "outputs": [],
      "source": [
        "max_story_len = max([len(data[0]) for data in all_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3-r0GqKvFg-",
        "outputId": "1db96d35-e0ee-4b64-a1c9-0032ea71cc4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "max_story_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "collapsed": true,
        "id": "ClRztEqAvFg-"
      },
      "outputs": [],
      "source": [
        "max_question_len = max([len(data[1]) for data in all_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K2dKeONvFg_",
        "outputId": "461b39d4-5c79-4ca5-a0a9-4ae361ceb355"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "max_question_len"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ9fEwcKvFg_"
      },
      "source": [
        "## Vectorizing the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_y4zzN0evFhA",
        "outputId": "2b207e98-d89d-42a1-bb15-477e04e18bbe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "collapsed": true,
        "id": "KasO_VKMvFhA"
      },
      "outputs": [],
      "source": [
        "# Reserve 0 for pad_sequences\n",
        "vocab_size = len(vocab) + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDjpBucFvFhB"
      },
      "source": [
        "-----------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "O5ozMGgWvFhB"
      },
      "outputs": [],
      "source": [
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "collapsed": true,
        "id": "AX922tOAvFhB"
      },
      "outputs": [],
      "source": [
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer(filters=[])\n",
        "tokenizer.fit_on_texts(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYscY7IdvFhC",
        "outputId": "a37e4b2a-5d3f-4d08-970c-9a3816e8f0a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dropped': 1,\n",
              " '?': 2,\n",
              " 'picked': 3,\n",
              " 'no': 4,\n",
              " 'daniel': 5,\n",
              " 'is': 6,\n",
              " 'moved': 7,\n",
              " 'john': 8,\n",
              " 'discarded': 9,\n",
              " 'yes': 10,\n",
              " 'down': 11,\n",
              " 'apple': 12,\n",
              " 'put': 13,\n",
              " 'left': 14,\n",
              " 'hallway': 15,\n",
              " 'to': 16,\n",
              " 'went': 17,\n",
              " 'bedroom': 18,\n",
              " 'kitchen': 19,\n",
              " 'football': 20,\n",
              " 'journeyed': 21,\n",
              " 'garden': 22,\n",
              " 'travelled': 23,\n",
              " 'in': 24,\n",
              " 'milk': 25,\n",
              " 'grabbed': 26,\n",
              " 'the': 27,\n",
              " 'took': 28,\n",
              " 'back': 29,\n",
              " 'bathroom': 30,\n",
              " 'up': 31,\n",
              " 'got': 32,\n",
              " 'there': 33,\n",
              " '.': 34,\n",
              " 'office': 35,\n",
              " 'sandra': 36,\n",
              " 'mary': 37}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "collapsed": true,
        "id": "0EZWte_4vFhC"
      },
      "outputs": [],
      "source": [
        "train_story_text = []\n",
        "train_question_text = []\n",
        "train_answers = []\n",
        "\n",
        "for story,question,answer in train_data:\n",
        "    train_story_text.append(story)\n",
        "    train_question_text.append(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "collapsed": true,
        "id": "8Ts2nfznvFhD"
      },
      "outputs": [],
      "source": [
        "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGGMNBWuvFhD",
        "outputId": "03d5523d-627a-4c44-fee9-dce11a76d344"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "len(train_story_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvpNETRkvFhE",
        "outputId": "cdf4f338-1587-4cde-f95b-1deecf430c54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "len(train_story_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "collapsed": true,
        "id": "qIouhnduvFhE"
      },
      "outputs": [],
      "source": [
        "# word_index = tokenizer.word_index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRe3XuRnvFhF"
      },
      "source": [
        "### Functionalize Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "collapsed": true,
        "id": "Bsugtc-VvFhF"
      },
      "outputs": [],
      "source": [
        "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
        "    '''\n",
        "    INPUT: \n",
        "    data: consisting of Stories,Queries,and Answers\n",
        "    word_index: word index dictionary from tokenizer\n",
        "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
        "    max_question_len: length of the longest question (used for pad_sequences function)\n",
        "\n",
        "    OUTPUT:\n",
        "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
        "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
        "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
        "    \n",
        "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
        "    '''\n",
        "\n",
        "    # X = STORIES\n",
        "    X = []\n",
        "    # Xq = QUERY/QUESTION\n",
        "    Xq = []\n",
        "    # Y = CORRECT ANSWER\n",
        "    Y = []\n",
        "    \n",
        "    for story, query, answer in data:\n",
        "        \n",
        "        # Grab the word index for every word in story\n",
        "        x = [word_index[word.lower()] for word in story]\n",
        "        # Grab the word index for every word in query\n",
        "        xq = [word_index[word.lower()] for word in query]\n",
        "        \n",
        "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
        "        # Index 0 is reserved so we're going to use + 1\n",
        "        y = np.zeros(len(word_index) + 1)\n",
        "        \n",
        "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
        "        #\n",
        "        y[word_index[answer]] = 1\n",
        "        \n",
        "        # Append each set of story,query, and answer to their respective holding lists\n",
        "        X.append(x)\n",
        "        Xq.append(xq)\n",
        "        Y.append(y)\n",
        "        \n",
        "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
        "        \n",
        "    # RETURN TUPLE FOR UNPACKING\n",
        "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "collapsed": true,
        "id": "v2MwEy-wvFhG"
      },
      "outputs": [],
      "source": [
        "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "collapsed": true,
        "id": "EorRJQZjvFhH"
      },
      "outputs": [],
      "source": [
        "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yukh2sIvFhH",
        "outputId": "ad456ae2-5ffb-44a2-ce91-5dd2b1c799d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ..., 27, 18, 34],\n",
              "       [ 0,  0,  0, ..., 27, 22, 34],\n",
              "       [ 0,  0,  0, ..., 27, 22, 34],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 27, 12, 34],\n",
              "       [ 0,  0,  0, ..., 27, 22, 34],\n",
              "       [ 0,  0,  0, ..., 12, 33, 34]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "inputs_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvHj1KQTvFhH",
        "outputId": "e5fdf20b-f210-41c1-a2b1-18ff8292ac5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6,  8, 24, 27, 19,  2],\n",
              "       [ 6,  8, 24, 27, 19,  2],\n",
              "       [ 6,  8, 24, 27, 22,  2],\n",
              "       ...,\n",
              "       [ 6, 37, 24, 27, 18,  2],\n",
              "       [ 6, 36, 24, 27, 22,  2],\n",
              "       [ 6, 37, 24, 27, 22,  2]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "queries_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im2uZAbfvFhI",
        "outputId": "c38558df-b4c1-422e-d51f-df976fa15cac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "answers_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWJt9K6svFhI",
        "outputId": "b4ad038f-ded3-4d7a-d5f8-f995b9916e7c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0.,   0.,   0.,   0., 503.,   0.,   0.,   0.,   0.,   0., 497.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "sum(answers_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amlRn_jXvFhI",
        "outputId": "3b84292e-5f2d-4d33-d5d6-d18aaa70f7d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "tokenizer.word_index['yes']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9pSclrcvFhJ",
        "outputId": "5a53305a-8d51-4575-be6e-934ca605061d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "tokenizer.word_index['no']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDk2VoT0vFhJ"
      },
      "source": [
        "## Creating the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "collapsed": true,
        "id": "p9rvUFx8vFhK"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
        "from keras.layers import add, dot, concatenate\n",
        "from keras.layers import LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KPr5FXYvFhK"
      },
      "source": [
        "### Placeholders for Inputs\n",
        "\n",
        "Recall we technically have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "collapsed": true,
        "id": "mQ0JUDR9vFhK"
      },
      "outputs": [],
      "source": [
        "input_sequence = Input((max_story_len,))\n",
        "question = Input((max_question_len,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "XQEhVvB2vFhL"
      },
      "source": [
        "### Building the Networks\n",
        "\n",
        "To understand why we chose this setup, make sure to read the paper we are using:\n",
        "\n",
        "* Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
        "  \"End-To-End Memory Networks\",\n",
        "  http://arxiv.org/abs/1503.08895"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IOTvPqIvFhL"
      },
      "source": [
        "## Encoders\n",
        "\n",
        "### Input Encoder m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "collapsed": true,
        "id": "du1f7mn9vFhL"
      },
      "outputs": [],
      "source": [
        "# Input gets embedded to a sequence of vectors\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
        "input_encoder_m.add(Dropout(0.3))\n",
        "\n",
        "# This encoder will output:\n",
        "# (samples, story_maxlen, embedding_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idmI5RqxvFhM"
      },
      "source": [
        "### Input Encoder c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "collapsed": true,
        "id": "5fG4wNBSvFhM"
      },
      "outputs": [],
      "source": [
        "# embed the input into a sequence of vectors of size query_maxlen\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
        "input_encoder_c.add(Dropout(0.3))\n",
        "# output: (samples, story_maxlen, query_maxlen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd-Apw7YvFhM"
      },
      "source": [
        "### Question Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "collapsed": true,
        "id": "5HKadKNYvFhN"
      },
      "outputs": [],
      "source": [
        "# embed the question into a sequence of vectors\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,\n",
        "                               output_dim=64,\n",
        "                               input_length=max_question_len))\n",
        "question_encoder.add(Dropout(0.3))\n",
        "# output: (samples, query_maxlen, embedding_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRa5OzOUvFhN"
      },
      "source": [
        "### Encode the Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "collapsed": true,
        "id": "_PHeDu3zvFhN"
      },
      "outputs": [],
      "source": [
        "# encode input sequence and questions (which are indices)\n",
        "# to sequences of dense vectors\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3pnmNc1vFhO"
      },
      "source": [
        "##### Use dot product to compute the match between first input vector seq and the query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "collapsed": true,
        "id": "6mlZi-ILvFhO"
      },
      "outputs": [],
      "source": [
        "# shape: `(samples, story_maxlen, query_maxlen)`\n",
        "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
        "match = Activation('softmax')(match)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQRCNhKhvFhP"
      },
      "source": [
        "#### Add this match matrix with the second input vector sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "collapsed": true,
        "id": "Ki3j5mqmvFhP"
      },
      "outputs": [],
      "source": [
        "# add the match matrix with the second input vector sequence\n",
        "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
        "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dX_O2VPGvFhP"
      },
      "source": [
        "#### Concatenate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "collapsed": true,
        "id": "7Vn3dOFdvFhQ"
      },
      "outputs": [],
      "source": [
        "# concatenate the match matrix with the question vector sequence\n",
        "answer = concatenate([response, question_encoded])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poTAtJzevFhQ",
        "outputId": "00e49065-42f5-43c7-98c2-03192989f279"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 6, 220) dtype=float32 (created by layer 'concatenate')>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "collapsed": true,
        "id": "QVShLvR4vFhQ"
      },
      "outputs": [],
      "source": [
        "# Reduce with RNN (LSTM)\n",
        "answer = LSTM(32)(answer)  # (samples, 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "collapsed": true,
        "id": "WKLlO95FvFhR"
      },
      "outputs": [],
      "source": [
        "# Regularization with Dropout\n",
        "answer = Dropout(0.5)(answer)\n",
        "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "collapsed": true,
        "id": "luy5hNVJvFhR"
      },
      "outputs": [],
      "source": [
        "# we output a probability distribution over the vocabulary\n",
        "answer = Activation('softmax')(answer)\n",
        "\n",
        "# build the final model\n",
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqIjUN5zvFhS",
        "outputId": "26256d12-c360-463a-e17f-1a47921e77d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 156)]        0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 6)]          0           []                               \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, None, 64)     2432        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " sequential_2 (Sequential)      (None, 6, 64)        2432        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 156, 6)       0           ['sequential[0][0]',             \n",
            "                                                                  'sequential_2[0][0]']           \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 156, 6)       0           ['dot[0][0]']                    \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, None, 6)      228         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 156, 6)       0           ['activation[0][0]',             \n",
            "                                                                  'sequential_1[0][0]']           \n",
            "                                                                                                  \n",
            " permute (Permute)              (None, 6, 156)       0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 6, 220)       0           ['permute[0][0]',                \n",
            "                                                                  'sequential_2[0][0]']           \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 32)           32384       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 32)           0           ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 38)           1254        ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 38)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 38,730\n",
            "Trainable params: 38,730\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "SbObvT5dvFhS",
        "outputId": "ba85697f-27fb-4082-bc4e-fbeefcc0001b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "313/313 [==============================] - 9s 8ms/step - loss: 0.9495 - accuracy: 0.4994 - val_loss: 0.6987 - val_accuracy: 0.5030\n",
            "Epoch 2/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.7080 - accuracy: 0.4962 - val_loss: 0.6933 - val_accuracy: 0.4960\n",
            "Epoch 3/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.6963 - accuracy: 0.4989 - val_loss: 0.6935 - val_accuracy: 0.5030\n",
            "Epoch 4/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6957 - accuracy: 0.4922 - val_loss: 0.6931 - val_accuracy: 0.5030\n",
            "Epoch 5/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6944 - accuracy: 0.5037 - val_loss: 0.6940 - val_accuracy: 0.4970\n",
            "Epoch 6/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6945 - accuracy: 0.4950 - val_loss: 0.6961 - val_accuracy: 0.4970\n",
            "Epoch 7/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6948 - accuracy: 0.4985 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 8/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6940 - accuracy: 0.5161 - val_loss: 0.6954 - val_accuracy: 0.5030\n",
            "Epoch 9/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6943 - accuracy: 0.4997 - val_loss: 0.6931 - val_accuracy: 0.5030\n",
            "Epoch 10/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6945 - accuracy: 0.4955 - val_loss: 0.6932 - val_accuracy: 0.5020\n",
            "Epoch 11/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6936 - accuracy: 0.5109 - val_loss: 0.6984 - val_accuracy: 0.4970\n",
            "Epoch 12/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6895 - accuracy: 0.5333 - val_loss: 0.6778 - val_accuracy: 0.6030\n",
            "Epoch 13/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6209 - accuracy: 0.6602 - val_loss: 0.5135 - val_accuracy: 0.7690\n",
            "Epoch 14/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.4893 - accuracy: 0.7816 - val_loss: 0.4269 - val_accuracy: 0.8410\n",
            "Epoch 15/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.4247 - accuracy: 0.8240 - val_loss: 0.3985 - val_accuracy: 0.8240\n",
            "Epoch 16/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3981 - accuracy: 0.8379 - val_loss: 0.3801 - val_accuracy: 0.8380\n",
            "Epoch 17/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3735 - accuracy: 0.8491 - val_loss: 0.3780 - val_accuracy: 0.8380\n",
            "Epoch 18/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3636 - accuracy: 0.8504 - val_loss: 0.3735 - val_accuracy: 0.8360\n",
            "Epoch 19/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3500 - accuracy: 0.8538 - val_loss: 0.3869 - val_accuracy: 0.8470\n",
            "Epoch 20/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3436 - accuracy: 0.8560 - val_loss: 0.3588 - val_accuracy: 0.8420\n",
            "Epoch 21/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3345 - accuracy: 0.8610 - val_loss: 0.3646 - val_accuracy: 0.8330\n",
            "Epoch 22/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3280 - accuracy: 0.8638 - val_loss: 0.3576 - val_accuracy: 0.8480\n",
            "Epoch 23/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3228 - accuracy: 0.8609 - val_loss: 0.3729 - val_accuracy: 0.8420\n",
            "Epoch 24/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3187 - accuracy: 0.8615 - val_loss: 0.3455 - val_accuracy: 0.8500\n",
            "Epoch 25/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3133 - accuracy: 0.8634 - val_loss: 0.3614 - val_accuracy: 0.8440\n",
            "Epoch 26/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3114 - accuracy: 0.8662 - val_loss: 0.3481 - val_accuracy: 0.8520\n",
            "Epoch 27/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3079 - accuracy: 0.8692 - val_loss: 0.3423 - val_accuracy: 0.8480\n",
            "Epoch 28/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3056 - accuracy: 0.8684 - val_loss: 0.3547 - val_accuracy: 0.8340\n",
            "Epoch 29/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3048 - accuracy: 0.8668 - val_loss: 0.3413 - val_accuracy: 0.8530\n",
            "Epoch 30/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2960 - accuracy: 0.8728 - val_loss: 0.3656 - val_accuracy: 0.8240\n",
            "Epoch 31/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2983 - accuracy: 0.8694 - val_loss: 0.3399 - val_accuracy: 0.8450\n",
            "Epoch 32/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2941 - accuracy: 0.8727 - val_loss: 0.3378 - val_accuracy: 0.8430\n",
            "Epoch 33/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2963 - accuracy: 0.8698 - val_loss: 0.3558 - val_accuracy: 0.8450\n",
            "Epoch 34/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2918 - accuracy: 0.8729 - val_loss: 0.3350 - val_accuracy: 0.8420\n",
            "Epoch 35/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2925 - accuracy: 0.8705 - val_loss: 0.3361 - val_accuracy: 0.8420\n",
            "Epoch 36/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2900 - accuracy: 0.8726 - val_loss: 0.3432 - val_accuracy: 0.8490\n",
            "Epoch 37/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2858 - accuracy: 0.8739 - val_loss: 0.3412 - val_accuracy: 0.8430\n",
            "Epoch 38/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2879 - accuracy: 0.8708 - val_loss: 0.3539 - val_accuracy: 0.8340\n",
            "Epoch 39/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2832 - accuracy: 0.8754 - val_loss: 0.3460 - val_accuracy: 0.8430\n",
            "Epoch 40/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2826 - accuracy: 0.8779 - val_loss: 0.3594 - val_accuracy: 0.8430\n",
            "Epoch 41/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2829 - accuracy: 0.8750 - val_loss: 0.3416 - val_accuracy: 0.8450\n",
            "Epoch 42/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2821 - accuracy: 0.8797 - val_loss: 0.3420 - val_accuracy: 0.8480\n",
            "Epoch 43/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2784 - accuracy: 0.8775 - val_loss: 0.3450 - val_accuracy: 0.8480\n",
            "Epoch 44/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2812 - accuracy: 0.8776 - val_loss: 0.3539 - val_accuracy: 0.8500\n",
            "Epoch 45/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2747 - accuracy: 0.8788 - val_loss: 0.3752 - val_accuracy: 0.8450\n",
            "Epoch 46/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2717 - accuracy: 0.8832 - val_loss: 0.3590 - val_accuracy: 0.8470\n",
            "Epoch 47/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2773 - accuracy: 0.8803 - val_loss: 0.3929 - val_accuracy: 0.8460\n",
            "Epoch 48/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2694 - accuracy: 0.8850 - val_loss: 0.3747 - val_accuracy: 0.8280\n",
            "Epoch 49/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2714 - accuracy: 0.8834 - val_loss: 0.3590 - val_accuracy: 0.8430\n",
            "Epoch 50/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2666 - accuracy: 0.8854 - val_loss: 0.3754 - val_accuracy: 0.8490\n",
            "Epoch 51/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2634 - accuracy: 0.8881 - val_loss: 0.4025 - val_accuracy: 0.8370\n",
            "Epoch 52/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2658 - accuracy: 0.8849 - val_loss: 0.3585 - val_accuracy: 0.8420\n",
            "Epoch 53/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2642 - accuracy: 0.8867 - val_loss: 0.3579 - val_accuracy: 0.8440\n",
            "Epoch 54/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2626 - accuracy: 0.8867 - val_loss: 0.3659 - val_accuracy: 0.8370\n",
            "Epoch 55/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2579 - accuracy: 0.8874 - val_loss: 0.3596 - val_accuracy: 0.8380\n",
            "Epoch 56/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2555 - accuracy: 0.8890 - val_loss: 0.4207 - val_accuracy: 0.8410\n",
            "Epoch 57/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2596 - accuracy: 0.8887 - val_loss: 0.4425 - val_accuracy: 0.8320\n",
            "Epoch 58/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2585 - accuracy: 0.8893 - val_loss: 0.3683 - val_accuracy: 0.8450\n",
            "Epoch 59/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2531 - accuracy: 0.8912 - val_loss: 0.3756 - val_accuracy: 0.8440\n",
            "Epoch 60/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2483 - accuracy: 0.8932 - val_loss: 0.3981 - val_accuracy: 0.8420\n",
            "Epoch 61/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2513 - accuracy: 0.8924 - val_loss: 0.4161 - val_accuracy: 0.8430\n",
            "Epoch 62/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2488 - accuracy: 0.8946 - val_loss: 0.3728 - val_accuracy: 0.8360\n",
            "Epoch 63/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2499 - accuracy: 0.8934 - val_loss: 0.4025 - val_accuracy: 0.8260\n",
            "Epoch 64/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2423 - accuracy: 0.8991 - val_loss: 0.4064 - val_accuracy: 0.8460\n",
            "Epoch 65/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2402 - accuracy: 0.8975 - val_loss: 0.4162 - val_accuracy: 0.8410\n",
            "Epoch 66/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2401 - accuracy: 0.8992 - val_loss: 0.4021 - val_accuracy: 0.8410\n",
            "Epoch 67/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2392 - accuracy: 0.8981 - val_loss: 0.4084 - val_accuracy: 0.8420\n",
            "Epoch 68/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2325 - accuracy: 0.9018 - val_loss: 0.3778 - val_accuracy: 0.8400\n",
            "Epoch 69/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2334 - accuracy: 0.9009 - val_loss: 0.4251 - val_accuracy: 0.8480\n",
            "Epoch 70/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2300 - accuracy: 0.9009 - val_loss: 0.4087 - val_accuracy: 0.8500\n",
            "Epoch 71/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2292 - accuracy: 0.9046 - val_loss: 0.3988 - val_accuracy: 0.8400\n",
            "Epoch 72/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2223 - accuracy: 0.9074 - val_loss: 0.4188 - val_accuracy: 0.8440\n",
            "Epoch 73/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2185 - accuracy: 0.9085 - val_loss: 0.3757 - val_accuracy: 0.8560\n",
            "Epoch 74/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2150 - accuracy: 0.9120 - val_loss: 0.3815 - val_accuracy: 0.8450\n",
            "Epoch 75/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2080 - accuracy: 0.9122 - val_loss: 0.3654 - val_accuracy: 0.8440\n",
            "Epoch 76/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2055 - accuracy: 0.9175 - val_loss: 0.3994 - val_accuracy: 0.8490\n",
            "Epoch 77/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1947 - accuracy: 0.9204 - val_loss: 0.3542 - val_accuracy: 0.8660\n",
            "Epoch 78/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1863 - accuracy: 0.9233 - val_loss: 0.3552 - val_accuracy: 0.8720\n",
            "Epoch 79/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1903 - accuracy: 0.9209 - val_loss: 0.3404 - val_accuracy: 0.8700\n",
            "Epoch 80/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1727 - accuracy: 0.9304 - val_loss: 0.3386 - val_accuracy: 0.8730\n",
            "Epoch 81/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1684 - accuracy: 0.9320 - val_loss: 0.3354 - val_accuracy: 0.8660\n",
            "Epoch 82/120\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.1615 - accuracy: 0.9355 - val_loss: 0.3265 - val_accuracy: 0.8780\n",
            "Epoch 83/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1480 - accuracy: 0.9404 - val_loss: 0.3096 - val_accuracy: 0.8760\n",
            "Epoch 84/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1415 - accuracy: 0.9421 - val_loss: 0.3393 - val_accuracy: 0.8900\n",
            "Epoch 85/120\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1441 - accuracy: 0.9432 - val_loss: 0.2811 - val_accuracy: 0.8850\n",
            "Epoch 86/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1376 - accuracy: 0.9433 - val_loss: 0.3330 - val_accuracy: 0.8890\n",
            "Epoch 87/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1330 - accuracy: 0.9466 - val_loss: 0.3056 - val_accuracy: 0.8860\n",
            "Epoch 88/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1355 - accuracy: 0.9456 - val_loss: 0.3012 - val_accuracy: 0.8870\n",
            "Epoch 89/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1279 - accuracy: 0.9489 - val_loss: 0.3476 - val_accuracy: 0.8920\n",
            "Epoch 90/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1218 - accuracy: 0.9517 - val_loss: 0.2950 - val_accuracy: 0.8890\n",
            "Epoch 91/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1233 - accuracy: 0.9528 - val_loss: 0.3144 - val_accuracy: 0.8910\n",
            "Epoch 92/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1140 - accuracy: 0.9556 - val_loss: 0.3026 - val_accuracy: 0.8870\n",
            "Epoch 93/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1134 - accuracy: 0.9548 - val_loss: 0.3544 - val_accuracy: 0.8870\n",
            "Epoch 94/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1078 - accuracy: 0.9548 - val_loss: 0.3201 - val_accuracy: 0.8990\n",
            "Epoch 95/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1169 - accuracy: 0.9538 - val_loss: 0.3234 - val_accuracy: 0.8950\n",
            "Epoch 96/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1111 - accuracy: 0.9582 - val_loss: 0.3164 - val_accuracy: 0.8990\n",
            "Epoch 97/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1050 - accuracy: 0.9600 - val_loss: 0.2963 - val_accuracy: 0.9010\n",
            "Epoch 98/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1060 - accuracy: 0.9603 - val_loss: 0.3278 - val_accuracy: 0.9000\n",
            "Epoch 99/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1057 - accuracy: 0.9594 - val_loss: 0.2922 - val_accuracy: 0.8940\n",
            "Epoch 100/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1008 - accuracy: 0.9621 - val_loss: 0.2988 - val_accuracy: 0.9000\n",
            "Epoch 101/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1000 - accuracy: 0.9625 - val_loss: 0.3148 - val_accuracy: 0.9040\n",
            "Epoch 102/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0993 - accuracy: 0.9627 - val_loss: 0.3177 - val_accuracy: 0.9030\n",
            "Epoch 103/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0879 - accuracy: 0.9643 - val_loss: 0.3065 - val_accuracy: 0.9160\n",
            "Epoch 104/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0939 - accuracy: 0.9642 - val_loss: 0.2579 - val_accuracy: 0.9120\n",
            "Epoch 105/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0871 - accuracy: 0.9671 - val_loss: 0.3075 - val_accuracy: 0.9070\n",
            "Epoch 106/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0972 - accuracy: 0.9642 - val_loss: 0.2692 - val_accuracy: 0.9120\n",
            "Epoch 107/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0854 - accuracy: 0.9690 - val_loss: 0.2722 - val_accuracy: 0.9130\n",
            "Epoch 108/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0811 - accuracy: 0.9696 - val_loss: 0.3001 - val_accuracy: 0.9090\n",
            "Epoch 109/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0819 - accuracy: 0.9700 - val_loss: 0.2791 - val_accuracy: 0.9140\n",
            "Epoch 110/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0793 - accuracy: 0.9688 - val_loss: 0.2935 - val_accuracy: 0.9150\n",
            "Epoch 111/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0801 - accuracy: 0.9703 - val_loss: 0.2954 - val_accuracy: 0.9150\n",
            "Epoch 112/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0777 - accuracy: 0.9733 - val_loss: 0.2545 - val_accuracy: 0.9180\n",
            "Epoch 113/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0738 - accuracy: 0.9724 - val_loss: 0.2914 - val_accuracy: 0.9180\n",
            "Epoch 114/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0703 - accuracy: 0.9737 - val_loss: 0.3089 - val_accuracy: 0.9140\n",
            "Epoch 115/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0719 - accuracy: 0.9749 - val_loss: 0.3038 - val_accuracy: 0.9170\n",
            "Epoch 116/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0737 - accuracy: 0.9749 - val_loss: 0.2952 - val_accuracy: 0.9180\n",
            "Epoch 117/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0705 - accuracy: 0.9755 - val_loss: 0.2945 - val_accuracy: 0.9240\n",
            "Epoch 118/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0680 - accuracy: 0.9753 - val_loss: 0.2876 - val_accuracy: 0.9230\n",
            "Epoch 119/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0678 - accuracy: 0.9750 - val_loss: 0.3063 - val_accuracy: 0.9220\n",
            "Epoch 120/120\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0674 - accuracy: 0.9771 - val_loss: 0.3271 - val_accuracy: 0.9210\n"
          ]
        }
      ],
      "source": [
        "# train\n",
        "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GC9vhzEvFhS"
      },
      "source": [
        "### Saving the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "collapsed": true,
        "id": "mafHBZJJvFhT"
      },
      "outputs": [],
      "source": [
        "filename = 'chatbot_120_epochs.h5'\n",
        "model.save(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dApisinHvFhT"
      },
      "source": [
        "## Evaluating the Model\n",
        "\n",
        "### Plotting Out Training History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "T2VwDW2nvFhT",
        "outputId": "dc105622-8aa6-4b88-cfae-1a088251f330",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX6nHss_vFhU"
      },
      "source": [
        "### Evaluating on Given Test Set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'chatbot_120_epochs.h5'"
      ],
      "metadata": {
        "id": "MHfvDj2Q1qft"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfbcyZKqvFhU",
        "outputId": "fab5e636-2719-468e-cad4-5dfead778dbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "model.load_weights(filename)\n",
        "pred_results = model.predict(([inputs_test, queries_test]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3H0XaEaQvFhU",
        "outputId": "204b0964-1bec-49c3-c571-7155a5e7d260"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mary',\n",
              " 'got',\n",
              " 'the',\n",
              " 'milk',\n",
              " 'there',\n",
              " '.',\n",
              " 'John',\n",
              " 'moved',\n",
              " 'to',\n",
              " 'the',\n",
              " 'bedroom',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "test_data[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoZMvfN5vFhV",
        "outputId": "528b4b07-d046-483b-c75c-391dfd2c9e84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mary got the milk there . John moved to the bedroom .\n"
          ]
        }
      ],
      "source": [
        "story =' '.join(word for word in test_data[0][0])\n",
        "print(story)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-dMibigvFhV",
        "outputId": "b7614126-8e92-4508-f3b7-3a89ef9b2303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is John in the kitchen ?\n"
          ]
        }
      ],
      "source": [
        "query = ' '.join(word for word in test_data[0][1])\n",
        "print(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kCkq9bQvFhV",
        "outputId": "3d537be7-adff-4e78-e0f0-bb09e229db72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Test Answer from Data is: no\n"
          ]
        }
      ],
      "source": [
        "print(\"True Test Answer from Data is:\",test_data[0][2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIC9OMadvFhW",
        "outputId": "49e4ffa3-4a1b-4909-8079-a8e64d6f2bce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted answer is:  no\n",
            "Probability of certainty was:  1.0\n"
          ]
        }
      ],
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfsh_00AvFhW"
      },
      "source": [
        "## Writing Your Own Stories and Questions\n",
        "\n",
        "Remember you can only use words from the existing vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMEKqUPtvFhW",
        "outputId": "60dc902b-397f-4cee-e9c1-4bf4917d6a59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjMEZfFzvFhX",
        "outputId": "9e93c523-cf95-4b13-9d85-376d9da8cf91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['John',\n",
              " 'left',\n",
              " 'the',\n",
              " 'kitchen',\n",
              " '.',\n",
              " 'Sandra',\n",
              " 'dropped',\n",
              " 'the',\n",
              " 'football',\n",
              " 'in',\n",
              " 'the',\n",
              " 'garden',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "# Note the whitespace of the periods\n",
        "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
        "my_story.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "collapsed": true,
        "id": "o5f9uk46vFhX"
      },
      "outputs": [],
      "source": [
        "my_question = \"Is the football in the garden ?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCGn0bAIvFhX",
        "outputId": "03692500-7c4b-4b6d-fc52-d79a556cdeba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "my_question.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "collapsed": true,
        "id": "Sp8OgaTSvFhY"
      },
      "outputs": [],
      "source": [
        "mydata = [(my_story.split(),my_question.split(),'yes')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "collapsed": true,
        "id": "kJzw3nNXvFhY"
      },
      "outputs": [],
      "source": [
        "my_story,my_ques,my_ans = vectorize_stories(mydata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_nbDcD-vFhY",
        "outputId": "c855dc47-51cb-4fa8-ac13-5e55381355da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        }
      ],
      "source": [
        "pred_results = model.predict(([ my_story, my_ques]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9u2RS_qvFhY",
        "outputId": "052231b5-085a-4a0f-e672-0c3817d23f63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted answer is:  yes\n",
            "Probability of certainty was:  0.9974969\n"
          ]
        }
      ],
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from platform import python_version\n",
        "print(python_version())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzTZfd8XwwIa",
        "outputId": "88f9d510-b234-464a-8ccf-e72a25027fb9"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.8.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM38T1P1yPf_",
        "outputId": "3c225981-06bf-42f6-bfcd-296d6dd69ab6"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "# import numpy\n",
        "print(pickle.format_version)\n",
        "print(np.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nSYBhX6ypeO",
        "outputId": "7008fa18-2619-428e-9329-3b2af3e480d6"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0\n",
            "1.21.6\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XQEhVvB2vFhL"
      ]
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}